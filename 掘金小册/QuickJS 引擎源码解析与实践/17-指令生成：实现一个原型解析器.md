前面的章节中我们关注的是指令执行的过程，接下来我们将开始探究指令序列是如何生成的。指令序列的生成离不开对源码的解析，我们将通过编写一个原型解析器来介绍源码解析的核心原理。

编译简述
----

在着手编码之前，我们先对齐一些基本概念。

我们平时所书写的源码，是无法被计算机直接执行的，因而需要一个过程，来将源码转化成机器可以执行的代码，这个转化的过程，就是编译。

与编译类似的还有「转义」，我们前端视野中最常见的「转义器 Transpiler」应该就是 [Babel](https://babeljs.io/ "https://babeljs.io/") 了，它可以将最新的 JS 语法转换成与之等价的老式的 JS 语法。

不难发现，编译和转义的相同点在于它们都是一个转换过程，而差别在于输入和输出所处的抽象层级不同 - 编译的输出相比其输入处在更低的层级（比如从 C 语言到汇编），而转义的输入和输出都处在相同的层级（JS 到 JS）。

另一个常常与编译一起出现的是「解释」，比如说某某语言是编译型还是解释型。解释型指的是直接解析源码并执行，通常来说会在对执行性能要求不高的脚本语言实现中使用该技术。编译和解释都是描述的编程语言执行的不同形式，但并不是和语言绑定的，比如 C 语言也有其解释器实现。

编译和解释也不是互斥的，比如早期的 PHP 实现使用的是解释执行的方式，而随着多年的演变，现如今它是先经编译成 OPCode 再执行，并且支持了 JIT。

说某某语言是编译型或者解释型现如今已经是含糊不清的了，非要说的话，应该说某某语言的解释器或者编译器。

### 编译的步骤

编译步骤可以简单地分为：

*   词法分析
    
*   语法分析
    
*   语义分析
    
*   生成中间代码
    
*   生成目标代码
    

「词法分析 Lexical Analysis」通过词法分析器「Lexer」来完成。词法分析器的具体工作是扫描字符串，并输出作为语法单元的「词素 Token」，因此它也被称为扫描器「Scanner」。

「语法分析 Syntax Analysis」通过语法分析器「Parser」来完成。语法分析器的具体工作是根据给定的语法「Grammar」来对词素进行分析，生成抽象语法树「AST - Abstract Syntax Tree」，抽象语法树用来描述程序的语法结构。

「语义分析 Semantic Analysis」用来保证代码中的语义规则的完整性，比如「类型检查 Type Checking」。

语义分析通过后会生成「符号表 Symbol Table」以及中间代码「Intermediate Code」。中间代码的作用是进一步将语法分析的结果进行处理，方便接下来在生成目标代码时的工作。

将编译的步骤进行这样的划分，目的是对编译器进行结构化，方便维护以及加快编译的过程。这些步骤仅是通用的划分，并不是所有的编译器实现都具备上面的步骤，这些步骤也不要求一定要严格地分步执行。

QuickJS 引擎采用的是将 JS 编译成 OPCode，再对 OPCode 进行解释执行的方式。对 OPCode 进行解释执行其实是模拟的硬件行为（CPU 也是对机器码进行解释，然后通过不同的电路单元来执行）。

为了更加形象地描述解析器的执行方式，接下来我们将实现一个简单的「Echo 语言」解析器。

解析器的工作是根据「某种规则」对源码进行解析，这里的「某种规则」就是我们常说「语法规则」。

语法规则
----

语法是编程语言的重要组成部分，就好比自然语言都有文法一样。有了语法之后，才能让大家有效地使用编程语言明确自己的程序需求。

语法由一组规则构成，这些规则又被称为「生产式 Production Rules」。

规则的组成形式为：

    规则名称 : 规则内容
    

> ECMA-262 标准中使用 `::` 作为词法规则名称和内容之间的分隔符

规则内容为「终结符 Terminal Symbol」和「非终结符 Nonterminal Symbol」的组合。我们来看一个例子，[ECMA-262 - Lexical Grammar](https://tc39.es/ecma262/#sec-lexical-grammar "https://tc39.es/ecma262/#sec-lexical-grammar") 一节给出了 JS 的词法规则，我们以其中的部分内容为例：

    IdentifierName ::
      IdentifierStart
      IdentifierName IdentifierPart
    
    IdentifierStart ::
      IdentifierStartChar
      \ UnicodeEscapeSequence
    
    IdentifierStartChar ::
      UnicodeIDStart
      $
      _
    
    UnicodeIDStart::
      any Unicode code point with the Unicode property "ID_Start"
    

*   规则 `IdentifierName` 规定的标识符名称的组成，以 `IdentifierStart` 开头，后面跟上若干 `IdentifierStart` 或 `IdentifierPart`
    
*   其中 `IdentifierStart` 可以继续展开，表示 `IdentifierStartChar` 或者 `\` 后面接着 `UnicodeEscapeSequence`
    
*   其中 `IdentifierStartChar` 可以继续展开，表示 `UnicodeIDStart` 或 `$` 或 `_`
    
*   其中 `UnicodeIDStart` 可以继续展开，表示具有 [ID\_Start](https://unicode.org/reports/tr31/#D1 "https://unicode.org/reports/tr31/#D1") 属性的码点
    
*   规则内容中可以继续展开的标识符称为非终结符，反之不能继续展开的称为终结符（比如 `$`）
    

如果我们将 `UnicodeIDStart` 简单地理解为英文字母，那么上面的规则就是我们熟知的「变量名需要以字母和下划线开头」。

词法规则
----

语法规则的内容按颗粒度由低到高可以分为：

*   词法规则
    
*   表达式规则
    
*   语句规则
    

比如，自然语言中包含陈述句、疑问句等各种句式，它们对应了语句规则。语句又是由单词构成的，描述单词的规则即为词法规则。

基于词法规则的解析就称为词法分析，分词的工作是将源码切割为一个个「词素 Token」，比如：

    function f() {}
    

经词法分析会产生下面的 Token 序列：

`function` `f` `(` `)` `{` `}`

词法分析其实是模拟人对自然语言的处理方式，比如我们在识别这句话的含义时：

    矿泉水不等于纯净水
    

识别的过程为：

*   首先不自觉地先识别句子中的词素：
    
    `矿泉水` `不等于` `纯净水`
    
*   有了词素之后，大脑就会开始根据它们的组织排列顺序来匹配句式，发现其为陈述句
    
*   接着进一步结合陈述句的语义，以及句中 Token 携带的信息，就能获得句子整体表达的含义
    

ECMA-262 的语法描述
--------------

在 [ECMA-262 - Notational Conventions](https://tc39.es/ecma262/#sec-notational-conventions "https://tc39.es/ecma262/#sec-notational-conventions") 一节中交代了 ECMA-262 在描述语法规则时用到的一些约定项。

了解这些约定项含义有助于我们理解和查阅标准中定义的 JS 语法规则，理清了语法规则后我们才好编写解析器。

我们看看其中几个出现频率较高的约定项。

### 分隔符

`::` 用于分隔词法规则和其规则内容。

`:` 用于分隔语法规则和其规则内容。

### 可缺省符号

下标 `opt` 表示该符号可以在其所处的位置是缺省的，比如：

![var_dec_opt](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5efeea536ff64d5d817d5f6a07420880~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=634&h=166&e=png&b=fefefe)

展开后为下面的内容：

    VariableDeclaration :
      BindingIdentifier
      BindingIdentifier Initializer
    

表示 `VariableDeclaration` 右侧可以是：

*   单独的 `BindingIdentifier`
    
*   或者是 `BindingIdentifier` 与 `Initializer` 的组合
    

### 语法规则参数

使用方括号括起来的下标称为 [Grammatical Parameters](https://tc39.es/ecma262/#sec-grammatical-parameters "https://tc39.es/ecma262/#sec-grammatical-parameters") 用于对一组组合规则进行简写，方括号中的参数可以为一个，也可以为逗号分隔的多个。

参数为一个且出现在生产式左侧时：

![return_param](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8fbef707e0b54501b8bbc8cff2352d5d~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=546&h=232&e=png&b=fefefe)

展开后的内容为：

    StatementList :
      ReturnStatement
      ExpressionStatement
    
    StatementList_Return :
      ReturnStatement
      ExpressionStatement
    

参数为多个，且出现在生产式左侧时，表示对它们的组合的简写：

![return_param_multi](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/054181c60706427d9aa478a36bfcd49f~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=536&h=230&e=png&b=fefefe)

展开后的内容为：

    StatementList :
      ReturnStatement
      ExpressionStatement
    
    StatementList_Return :
      ReturnStatement
      ExpressionStatement
    
    StatementList_In :
      ReturnStatement
      ExpressionStatement
    
    StatementList_Return_In :
      ReturnStatement
      ExpressionStatement
    

可以发现如果仅规则名称中存在参数，那么相当于为一个规则创建多个别名。

语法规则参数也可以出现在生产式右侧，比如出现在右侧且具有 `+` 前缀时：

![rule_param_rhs](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8e8319ba40064f3381ab0fa8cbf6d833~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=618&h=240&e=png&b=ffffff)

展开后的内容为：

    StatementList :
      ReturnStatement
      ExpressionStatement_In
    

出现在右侧且具有 `~` 前缀时：

![rule_param_rhs_minus](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/87636c5529c54e6dbc8ae3c31c832415~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=598&h=240&e=png&b=fefefe)

展开后的内容为：

    StatementList :
      ReturnStatement
      ExpressionStatement
    

可以发现参数单出现在右侧时，仅表示所处位置项的后缀形式：`+` 表示有紧跟其后的字符作为后缀，`~` 表示没有紧跟其后的字符作为后缀。

右侧参数也是可以和可缺省符号组合使用的：

![rule_params_rhs_opt](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60bbc41d48d44d89a6f5cbde7ba2f5a9~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=770&h=196&e=png&b=fefefe)

展开后的内容为：

    VariableDeclaration :
      BindingIdentifier
      BindingIdentifier Initializer_In
    

上面的参数都是单独出现在左侧或者右侧，如果左右侧同时出现参数的话，它们之间是可以联动的。比如右侧参数通过 `?` 将其出现和左侧参数绑定：

![rule_params_both_ques](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/32e45c3ccd084e268b8e9dfc40d20a28~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=704&h=182&e=png&b=fefefe)

展开的内容为：

    VariableDeclaration :
      BindingIdentifier
      BindingIdentifier Initializer
    
    (* or *)
    
    VariableDeclaration_In :
      BindingIdentifier
      BindingIdentifier Initializer_In
    

右侧参数还可以通过 `+` 前缀表示仅左侧使用了参数时才出现：

![rule_params_both_plus](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/83e110bf010a4089a66285440514db2d~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=592&h=242&e=png&b=fefefe)

展开的内容为：

    StatementList :
      ExpressionStatement
    
    (* or *)
    
    StatementList_Return :
      ReturnStatement
      ExpressionStatement
    

右侧参数还可以通过 `~` 前缀表示和左侧的参数互斥（左侧没有出现时才出现）：

![rule_params_both_nega](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1dac045f7f1d4e00950ffef1234cef9b~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=576&h=230&e=png&b=fefefe)

展开后的内容为：

    StatementList :
      ReturnStatement
      ExpressionStatement
    
    (* or *)
    
    StatementList_Return :
      ExpressionStatement
    

Echo 的语法
--------

在给出 Echo 的语法之前，我们先了解一下它的功能。

Echo 的功能非常简单，只有 2 个：

1.  将数值和字符串内容输出到控制台
    
        echo "hello world"
        
    
2.  执行基本的算数运算
    
        echo 1 + 2
        
    

下面是 Echo 的语法规则：

    Program :
      StatementList
    
    StatementList :
      EchoStatement
      StatementList EchoStatement
    
    EchoStatement :
      echo Expression
    
    Expression :
      StringLiteral
      AdditiveExpression
    
    AdditiveExpression :
      MultiplicativeExpression
      AdditiveExpression + AdditiveExpression
      AdditiveExpression - AdditiveExpression
    
    MultiplicativeExpression :
      DecimalIntegerLiteral
      MultiplicativeExpression MultiplicativeOperator MultiplicativeExpression
    
    MultiplicativeOperator : one of
      * / %
    
    StringLiteral ::
      " DoubleStringCharacters_opt "
    
    DoubleStringCharacters ::
      DoubleStringCharacter DoubleStringCharacters_opt
    
    DoubleStringCharacter ::
      SourceCharacter but not one of " or LineTerminator
    
    LineTerminator ::
      <LF>
    
    DecimalIntegerLiteral ::
      0
      NonZeroDigit
      NonZeroDigit DecimalDigits
    
    NonZeroDigit :: one of
      1 2 3 4 5 6 7 8 9
    
    DecimalDigits ::
      DecimalDigit
      DecimalDigits DecimalDigit
    
    DecimalDigit :: one of
      0 1 2 3 4 5 6 7 8 9
    

上面的语法规则描述方式沿用了 ECMA-262 中的形式，但这并不是唯一的形式。还有其他的形式可以用于描述语法规则，它们都由 [「巴科斯范式 Backus–Naur form (BNF)」](https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form "https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form") 演变而来。

比如使用 [ANTLR](https://github.com/antlr/antlr4 "https://github.com/antlr/antlr4") 的语法可以将表达式部分的规则缩减为：

    Expression
      : StringLiteral
      | AdditiveExpression
      ;
    
    AdditiveExpression
      : AdditiveExpression ( '*' | '/' | '%' ) AdditiveExpression
      | AdditiveExpression ( '+' | '-' ) AdditiveExpression
      | DecimalIntegerLiteral
      ;
    

也可以使用 [W3C's EBNF](https://www.w3.org/TR/xml/#sec-notation "https://www.w3.org/TR/xml/#sec-notation") 来重写上面的语法规则：

    Program ::= StatementList
    
    StatementList ::= EchoStatement*
    
    EchoStatement ::= 'echo' Expression
    
    Expression ::= StringLiteral | AdditiveExpression
    
    AdditiveExpression ::= MultiplicativeExpression ( ( '+' | '-' ) MultiplicativeExpression )*
    
    MultiplicativeExpression ::= DecimalIntegerLiteral ( ( '*' | '/' | '%' ) DecimalIntegerLiteral )*
    
    StringLiteral ::= '"' [^"\n]* '"'
    
    DecimalIntegerLiteral ::= '0' | [1-9] [0-9]*
    

还可以通过一些工具将语法规则可视化，比如将上面的规则代码粘贴到 [Railroad Diagram Generator](https://bottlecaps.de/rr/ui "https://bottlecaps.de/rr/ui") 可以提到下面的图形化展示：

![echo_grammar_diagram](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ac6df4f1d73b411f8f58e78e245dd03a~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1370&h=4334&e=png&b=fefbec)

Source
------

在实现词法解析器之前，我们先实现一个辅助类 Source 用于简化对源码的操作。

### 构造函数

    class Source {
      ch: string;
      ofst: number;
      line: number;
      col: number;
    
      constructor(public code = "") {
        this.ch = "";
        this.ofst = 0;
        this.line = 1;
        this.col = 0;
      }
    }
    

上面是 `Source` 的构造函数，构造函数参数只有一个 `code`，表示需要解析的源码内容。

`Source` 有这几个属性：

*   `ch` 表示当前读取的字符，为了简单考虑，我们的解析器将只处理 ASCII 字符集
    
*   `ofst` 表示当前读取的字符在源码内容中的位置，这个位置是一个相对源码首个字符位置的偏移量 offset
    
*   `line` 表示当前读取的字符在源码内的行号
    
*   `col` 表示当前读取的字符在源码内的列号
    

### 读取字符

我们先看看读取字符的方法：

    class Source {
      // ...
      read(cnt = 1) {
        const ret: string[] = [];
        while (cnt) {
          this.ch = this.code[this.ofst++];
          if (this.ch === NL) {
            this.line++;
            this.col = 1;
          } else if (this.ch === undefined) {
            this.ch = EOF;
            break;
          } else {
            this.col++;
          }
          ret.push(this.ch);
          cnt--;
        }
        return ret.join("");
      }
      // ...
    }
    

在 `read` 方法中：

*   可以读取一个或者多个字符
    
*   判断读入的字符是否为换行符，以便记录行列号
    

为了简单我们只考虑源码中换行符为 `\n` 的情况，因为这是如今比较常见的情况，其他情况包括：

*   macOS 中可能使用的 `\r` 作为换行符
    
*   Windows 中可能使用的 `\r\n` 作为换行符
    
*   Unicode 中包含的具有换行语义的码点，比如 [<LS>](https://www.compart.com/en/unicode/U+2028 "https://www.compart.com/en/unicode/U+2028")
    

### 解析状态

我们可以将 `Source` 处理源码过程中的状态信息抽出为一个类 `SourceState`：

    class SourceState {
      constructor(
        public ch: string,
        public ofst: number,
        public line: number,
        public col: number
      ) {}
    }
    

然后我们在 `Source` 中增加两个方法，可以读取和恢复状态：

    class Source {
      // ...
      getState() {
        return new SourceState(this.ch, this.ofst, this.line, this.col);
      }
    
      setState(s: SourceState) {
        this.ch = s.ch;
        this.ofst = s.ofst;
        this.line = s.line;
        this.col = s.col;
      }
      // ...
    }
    

### 预读字符

状态可以恢复之后，实现字符预读的功能就变得水到渠成：

    class Source {
      // ...
      peek(cnt = 1) {
        const s = this.getState();
        const ret = this.read(cnt);
        this.setState(s);
        return ret;
      }
      // ...
    }
    

预读就是在不改变当前状态的情况下，预读下 N 个位置字符。我们可以先保存当前的状态，然后读取一个字符后将状态恢复。

### 整体实现

`Source` 的完整代码为：

点击展开

    // 0x03 在 ascii 表中的含义为 end of text
    export const EOF = "\x03";
    export const NL = "\n";
    
    export class Position {
      static Invalid = new Position(0, 0, 0);
    
      constructor(public ofst: number, public line: number, public col: number) {}
    }
    
    class SourceState {
      constructor(
        public ch: string,
        public ofst: number,
        public line: number,
        public col: number
      ) {}
    }
    
    export class Source {
      ch: string;
      ofst: number;
      line: number;
      col: number;
    
      constructor(public code = "") {
        this.ch = "";
        this.ofst = 0;
        this.line = 1;
        this.col = 0;
      }
    
      read(cnt = 1) {
        const ret: string[] = [];
        while (cnt) {
          this.ch = this.code[this.ofst++];
          if (this.ch === NL) {
            this.line++;
            this.col = 1;
          } else if (this.ch === undefined) {
            this.ch = EOF;
            break;
          } else {
            this.col++;
          }
          ret.push(this.ch);
          cnt--;
        }
        return ret.join("");
      }
    
      eof() {
        return this.ch === EOF;
      }
    
      getPos() {
        return new Position(this.ofst, this.line, this.col);
      }
    
      getState() {
        return new SourceState(this.ch, this.ofst, this.line, this.col);
      }
    
      setState(s: SourceState) {
        this.ch = s.ch;
        this.ofst = s.ofst;
        this.line = s.line;
        this.col = s.col;
      }
    
      peek(cnt = 1) {
        const s = this.getState();
        const ret = this.read(cnt);
        this.setState(s);
        return ret;
      }
    }

我们可以加入几个简单的单元测试，这样后续如果 `Source` 的实现有调整也可以继续保持其功能的完整性：

    if (Deno.env.get("TEST") === "source") {
      const s = new Source(`abc
    def g`);
      let c = s.read();
      console.assert(c === "a", "read");
      console.assert(s.peek(2) === "bc", "peek 2");
      console.assert(s.read(4) === "bc\nd", "read 4");
      console.assert(s.line === 2, "line changed");
      console.assert(s.col === 2, "col changed");
      console.assert(s.read(5) === "ef g", "read to eof");
      console.assert(s.ch === EOF, "eof");
    }
    

可以将上面的内容粘贴到 `Source` 的底部，然后通过下面的命令执行单测：

    export TEST=source && deno run --allow-env source.ts && echo $?
    

看到控制台输出 0 的话即表示单测通过。

Lexer
-----

词法解析器的工作是根据词法规则进行分词，也就是对源码输入进行解析，产生一个个 Tokens。

词法解析器的结构可以为：

    class Lexer {
      constructor(public source: Source) {}
    
      next() {}
    
      isWhitespace(ch: string) {}
    
      skipWhitespace() {}
    
      readString() {}
    
      readNumber(loc: Position) {}
    
      readEcho(loc: Position) {}
    
      err() {}
    }
    

Lexer 的构造函数参数只有一个，即 Source 的实例，我们通过它来操作源码。

上面的方法最核心的是 `next` 方法，每次调用该方法，都会读取一部分源码内容并解析，产生一个 Token。

### Token

词法分析器的处理结果是 Token 序列，我们看看其相关的数据结构：

    enum TokenKind {
      EOF = "EOF",
      ECHO = "ECHO",
      STR = "STR",
      NUM = "NUM",
      MUL = "MUL",
      DIV = "DIV",
      ADD = "ADD",
      SUB = "SUB",
      MOD = "MOD",
    }
    
    class Token {
      constructor(
        public kind: TokenKind,
        public value = "",
        public loc = Position.Invalid
      ) {}
    }
    

Token 类有 3 个属性：

*   `kind` 表示 Token 的类型，比如是字符串，还是关键字 `echo`
    
*   `value` 表示 Token 内包含的源码内容，比如字符串 Token，该字段的值为 `"` 之间的内容
    
*   `loc` 表示 Token 对应的源码位置，这里我们简单地保存一下起始位置
    

### next

`next` 的方法的实现为：

    class Lexer {
      // ...
      next() {
        this.skipWhitespace();
    
        const loc = this.source.getPos();
        const ch = this.source.read();
    
        if (ch === '"') return this.readString();
        if (ch === "e") return this.readEcho(loc);
    
        if (ch >= "1" && ch <= "9") return this.readNumber(loc);
    
        if (ch === "+") return new Token(TokenKind.ADD, ch, loc);
        if (ch === "-") return new Token(TokenKind.SUB, ch, loc);
        if (ch === "*") return new Token(TokenKind.MUL, ch, loc);
        if (ch === "/") return new Token(TokenKind.DIV, ch, loc);
        if (ch === "%") return new Token(TokenKind.MOD, ch, loc);
    
        if (this.source.eof()) return new Token(TokenKind.EOF);
    
        throw new Error(this.err());
      }
    
      isWhitespace(ch: string) {
        return ch === " " || ch === "\t" || ch === NL;
      }
    
      skipWhitespace() {
        while (this.isWhitespace(this.source.peek())) {
          this.source.read();
        }
      }
      // ...
    }
    

上面代码对应的解释为：

*   首先通过调用 `skipWhitespace` 来跳过空白字符
    
    比如空格、制表符这些，它们的作用是分隔 Token，因此在解析过程中需要将它们跳过
    
*   然后通过调用 `Source::read` 方法来读取一个字符，通过对该字符进行判断，路由到不同的 Token 处理方法。比如发现是 `"`，就调用 `readString` 方法来解析字符串
    
*   依次处理所有可能的 Token 分支，如果均未匹配到，则抛出异常。`err` 方法会对异常的消息做简单的格式化处理。
    

### readString

`readString` 方法的实现为：

    class Lexer {
      // ...
      readString() {
        const loc = this.source.getPos();
        const v: string[] = [];
        while (true) {
          let ch = this.source.read();
          if (ch === '"') break;
          if (ch === NL || this.source.eof()) throw new Error(this.err());
          v.push(ch);
        }
        return new Token(TokenKind.STR, v.join(""), loc);
      }
      // ...
    }
    

下图为字符串字面量的词法规则对应的图示：

![lex_str](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/58cfe74876b84239b20df55948922f36~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=654&h=372&e=png&b=fefcf1)

可以看出图的通路其实就对应的函数体中的 `while` 循环中的内容：

*   读取一个字符，如果为 `"` 则表示匹配到了字符串末尾，那么跳出循环
    
*   如果为换行符或者 EOF，则表示字符串没有被正确的关闭，因此需要抛出异常
    
*   处理了异常情况后，剩下的字符则为字符串内容
    

### readNumber

`readNumber` 方法的实现为：

    class Lexer {
      // ...
      readNumber(loc: Position) {
        const v: string[] = [this.source.ch];
        while (true) {
          let ch = this.source.read();
          if (ch >= "0" && ch <= "9") v.push(ch);
          else if (this.isWhitespace(ch) || this.source.eof()) break;
          else throw new Error(this.err());
        }
        return new Token(TokenKind.NUM, v.join(""), loc);
      }
      // ...
    }
    

下图为数值字面量的词法规则对应的图示：

![lex_num](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9b14050ee4474e4c8429e0fecbaa7ded~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=618&h=474&e=png&b=fefcf1)

代码中的 `while` 循环可以对照上图的通路来理解：

*   读取一个字符，如果为数值，且当前没有前导 `0`：
    
    *   如果为 `0`，则判断是否需要设置前导 `0` 标记
        
    *   将字符添加到 Token 内容后继续读取下一个字符
        
*   到这里读入的字符可能为：
    
    1.  空白字符或者 EOF
        
    2.  数值，但是有前导 `0`
        
    3.  非数值，且与之前的数值字符之间没有分隔
        
    
    对于第 1 种情况，表示数值字面量已经正常关闭，其余情况则抛出异常
    

### readEcho

`readEcho` 方法的实现比较简单：

    class Lexer {
      // ...
      readEcho(loc: Position) {
        const v = "e" + this.source.read(3);
        if (v !== "echo") throw new Error(this.err());
        return new Token(TokenKind.ECHO, v, loc);
      }
    
      err() {
        return `Unexpected char \`${this.source.ch}\` at line: ${this.source.line} column: ${this.source.col}`;
      }
      // ...
    }
    

我们直接判断 `e` 开头的内容是否为 `echo` 即可。

`err` 方法中我们会加上异常发生的行列号。

### 整体实现

`Lexer` 的完整代码为：

点击展开

    import { NL, Position, Source } from "./source.ts";
    
    export enum TokenKind {
      EOF = "EOF",
      ECHO = "ECHO",
      STR = "STR",
      NUM = "NUM",
      MUL = "MUL",
      DIV = "DIV",
      ADD = "ADD",
      SUB = "SUB",
      MOD = "MOD",
    }
    
    export class Token {
      constructor(
        public kind: TokenKind,
        public value = "",
        public loc = Position.Invalid
      ) {}
    }
    
    export class Lexer {
      constructor(public source: Source) {}
    
      next() {
        this.skipWhitespace();
    
        const loc = this.source.getPos();
        const ch = this.source.read();
    
        if (ch === '"') return this.readString();
        if (ch === "e") return this.readEcho(loc);
    
        if (ch >= "1" && ch <= "9") return this.readNumber(loc);
    
        if (ch === "+") return new Token(TokenKind.ADD, ch, loc);
        if (ch === "-") return new Token(TokenKind.SUB, ch, loc);
        if (ch === "*") return new Token(TokenKind.MUL, ch, loc);
        if (ch === "/") return new Token(TokenKind.DIV, ch, loc);
        if (ch === "%") return new Token(TokenKind.MOD, ch, loc);
    
        if (this.source.eof()) return new Token(TokenKind.EOF);
    
        throw new Error(this.err());
      }
    
      isWhitespace(ch: string) {
        return ch === " " || ch === "\t" || ch === NL;
      }
    
      skipWhitespace() {
        while (this.isWhitespace(this.source.peek())) {
          this.source.read();
        }
      }
    
      readString() {
        const loc = this.source.getPos();
        const v: string[] = [];
        while (true) {
          let ch = this.source.read();
          if (ch === '"') break;
          if (ch === NL || this.source.eof()) throw new Error(this.err());
          v.push(ch);
        }
        return new Token(TokenKind.STR, v.join(""), loc);
      }
    
      readNumber(loc: Position) {
        const v: string[] = [this.source.ch];
        let zero = false;
        while (true) {
          let ch = this.source.read();
          if (ch >= "0" && ch <= "9" && !zero) {
            if (ch === "0" && v.length === 0) zero = true;
            v.push(ch);
            continue;
          }
          if (this.isWhitespace(ch) || this.source.eof()) break;
          else throw new Error(this.err());
        }
        return new Token(TokenKind.NUM, v.join(""), loc);
      }
    
      readEcho(loc: Position) {
        const v = "e" + this.source.read(3);
        if (v !== "echo") throw new Error(this.err());
        return new Token(TokenKind.ECHO, v, loc);
      }
    
      err() {
        return `Unexpected char \`${this.source.ch}\` at line: ${this.source.line} column: ${this.source.col}`;
      }
    }

我们可以加入几个简单的单元测试，这样后续如果 `Lexer` 的实现有调整也可以继续保持其功能的完整性：

    if (Deno.env.get("TEST") === 'lexer') {
      let s = new Source(`echo "hello"
    echo 1 + 2`);
      let lexer = new Lexer(s);
      console.assert(lexer.next().value === "echo", "echo");
      console.assert(lexer.next().value === "hello", "hello");
    
      console.assert(lexer.next().value === "echo", "echo");
      console.assert(lexer.next().value === "1", "1");
      console.assert(lexer.next().value === "+", "+");
      console.assert(lexer.next().value === "2", "2");
    
      s = new Source(`echo "hello"
    echo 1 + 2`);
      lexer = new Lexer(s);
      const tokens: Token[] = [];
      let tok: Token;
      do {
        tok = lexer.next();
        tokens.push(tok);
      } while (tok.kind !== TokenKind.EOF);
      console.log(tokens);
    }
    

可以将上面的内容粘贴到 `Lexer` 的底部，然后通过下面的命令执行单测：

    export TEST=lexer && deno run --allow-env lexer.ts && echo $?
    

看到控制台输出 0 的话即表示单测通过。上面的代码中我们还打印了解析后的 Token 序列，因此还会看到类似的输出：

    [
      Token { kind: "ECHO", value: "echo", loc: Position { ofst: 0, line: 1, col: 0 } },
      Token { kind: "STR", value: "hello", loc: Position { ofst: 6, line: 1, col: 6 } },
      Token { kind: "ECHO", value: "echo", loc: Position { ofst: 13, line: 2, col: 1 } },
      Token { kind: "NUM", value: "1", loc: Position { ofst: 18, line: 2, col: 6 } },
      Token { kind: "ADD", value: "+", loc: Position { ofst: 20, line: 2, col: 8 } },
      Token { kind: "NUM", value: "2", loc: Position { ofst: 22, line: 2, col: 10 } },
      Token { kind: "EOF", value: "", loc: Position { ofst: 0, line: 0, col: 0 } }
    ]
    

Parser
------

语法解析器的工作内容是，根据语法规则对源码输入进行解析，产生的结果为结构化后的源码内容。

### AST

语法解析在整个编译的环节中属于前端工作，其处理结果还会被后续流程消化：

![parse_phase](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d20a08073e604854b9b9b45bfe75c4d7~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1616&h=258&e=png&b=fefefe)

因此，经解析器处理后的结构化的源码内容，就是采用某种数据结构、将源码中的信息进行保存，方便后续的流程的处理。

这样的数据结构有多种，比如 [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree "https://en.wikipedia.org/wiki/Abstract_syntax_tree")，[ASG](https://en.wikipedia.org/wiki/Abstract_semantic_graph "https://en.wikipedia.org/wiki/Abstract_semantic_graph")，[Three-address code](https://en.wikipedia.org/wiki/Three-address_code "https://en.wikipedia.org/wiki/Three-address_code") 等。最常用的为 AST，全称是 Abstract syntax tree。

选择 AST 是因为我们的语法规则基本都是有层次的，而树形结构可以很方便地体现这样的层次关系：

![ast](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/00bc4b08b37a41998d0003010b04ba81~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.jpg#?w=1402&h=602&e=png&b=ffffff)

我们可以将 AST 的部分实现为：

    enum NodeKind {
      PROG = "PROG",
      ECHO = "ECHO_STMT",
    
      BIN = "BIN_EXPR",
    
      STR = "STR",
      NUM = "NUM",
    }
    
    interface Node {
      kind: NodeKind;
      loc: Position;
    }
    
    class Prog {
      kind = NodeKind.PROG;
      loc: Position;
      body: Node[] = [];
    }
    
    class EchoStmt {
      kind = NodeKind.ECHO;
      loc: Position;
      expr: Node;
    }
    

需要说明的是：

*   枚举 `NodeKind` 罗列了节点可能的类型
    
*   定义了表示节点的接口 `Node`，包含两个基本字段，表示类型的 `kind` 以及位置信息 `loc`
    
*   具体的节点类并没有采用继承的方式，这样可以让类结构显得扁平简单
    

### Top-down parsing

通常来说，手写的解析器会采用 Top-down 算法来编写（比如 quickjs 和 TypeScript），好处是方便理解和维护。

我们来简单理解 Top-down 算法，假设有语法：

    Program ::= StatementList
    
    StatementList ::= EchoStatement*
    
    EchoStatement ::= 'echo' Expression
    

可与发现语法规则从上往下呈包含关系，我们可以为每个规则编写对应函数，然后让这些函数之间相互调用来完成解析：

    function parseProg() {
      parseStmtList();
    }
    
    function parseStmtList() {
      while (x) parseEchoStmt();
    }
    
    function parseEchoStmt() {
      must("echo");
      parseExpr();
    }
    
    function parseExpr() {}
    

可见 Top-down 的解析函数基本可以和语法规则对应上，解析器的编写只需要对照语法规则即可。

### 左递归

Top-down 解析也不是没有缺点，它对语法规则有一定的要求，比如不能出现左递归：

    AdditiveExpression
      : AdditiveExpression ( '*' | '/' | '%' ) AdditiveExpression
      | AdditiveExpression ( '+' | '-' ) AdditiveExpression
      | DecimalIntegerLiteral
      ;
    

如果我们参照上面的语法规则，将 `parseAddExpr` 函数编写为：

    function parseAddExpr() {
      parseAddExpr(); // 1
      must("*");
      parseAddExpr();
    }
    

可以发现位置 `1` 处的递归调用因为没有消耗任何的输入，会使得解析过程陷入死循环。

解决方式是将左递归的语法变换为与它们等价的、不包含左递归的形式，这个变换操作称为[「左递归消除 Left recursion elimination」](https://en.wikipedia.org/wiki/Left_recursion#Removing_left_recursion "https://en.wikipedia.org/wiki/Left_recursion#Removing_left_recursion")。

左递归消除的细节就不展开讨论了，我们的 `echo` 语法的 W3C's EBNF 表示形式已经消除了左递归。

### 优先级

在解析表达式时，当表达式中出现多个操作符时，为了解决它们执行的先后顺序，就需要引入「优先级 Precedence」的概念。

> JS 中的优先级定义可以参考 [Operator precedence](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_Precedence "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_Precedence")。

比如表达式 `2 * 3 + 4` 应该被解析成：

        node
        / | \
     node +  4
     / | \
    2  *  3
    

而不是 `2 * (3 + 4)`：

     node
     / | \
    2  * node
        / | \
       3  +  4
    

通过观察上面正确的树形结构可以发现，具有较高优先级的表达式 `*`，将作为较低优先级的表达式 `+` 的子节点。

在使用 Top-down 解析时，通常会将语法规则进行调整，将具有较低优先级的表达式作为层级更高的语法规则，以便 Top-down 解析时正确地生成包含关系。

比如下面的语法体现了优先级：

    AdditiveExpression ::= MultiplicativeExpression ( ( '+' | '-' ) MultiplicativeExpression )*
    
    MultiplicativeExpression ::= DecimalIntegerLiteral ( ( '*' | '/' | '%' ) DecimalIntegerLiteral )*
    

对应的解析函数实现可以类似：

    function parseAddExpr() {
      const lhs = parseMulExpr();
      const op = must("+", "-");
      const rhs = parseMulExpr();
      return {
        op,
        lhs,
        rhs,
      };
    }
    
    function parseMulExpr() {
      const lhs = parseNum();
      const op = must("*", "/", "%");
      const rhs = parseNum();
      return {
        op,
        lhs,
        rhs,
      };
    }
    

### 结合性

另一个在解析表达式时需要注意的是操作符的「结合性 Associativity」。

结合性解决的是，当表达式中出现多个优先级相同的操作符时，它们的执行顺序应当如何确定的问题。

比如在 JS 中 `**` 是右结合的，因此表达式 `2 ** 3 ** 4` 应该被解析成：

      node
      / | \
     2  ** node
           / | \
          3  ** 4
    

而不是 `(2 ** 3) ** 4`：

        node
        / | \
     node **  4
     / | \
    2  **  3
    

结合性也可以通过调整语法规则来体现，比如标准中的 [ExponentiationExpression](https://tc39.es/ecma262/#prod-ExponentiationExpression "https://tc39.es/ecma262/#prod-ExponentiationExpression") 规则：

    ExponentiationExpression ::
      UnaryExpression
      UpdateExpression ** ExponentiationExpression
    

`**` 左侧为优先级高于其的表达式，右侧调用自身，这样使用 Top-down 解析时，节点就自然地完成了右结合

### 完整代码

`Parser` 的完整代码为：

点击展开

    import { Lexer, Token, TokenKind } from "./lexer.ts";
    import { Position, Source } from "./source.ts";
    
    enum NodeKind {
      PROG = "PROG",
      ECHO = "ECHO_STMT",
    
      BIN = "BIN_EXPR",
    
      STR = "STR",
      NUM = "NUM",
    }
    
    export interface Node {
      kind: NodeKind;
      loc: Position;
    }
    
    export class Prog {
      kind = NodeKind.PROG;
      loc: Position;
      body: Node[] = [];
    }
    
    export class EchoStmt {
      kind = NodeKind.ECHO;
      loc: Position;
      expr: Node;
    }
    
    export class BinExpr {
      kind = NodeKind.BIN;
      loc: Position;
      op: TokenKind;
      lhs: Node;
      rhs: Node;
    }
    
    export class Str {
      kind = NodeKind.STR;
      loc: Position;
      val: string;
    }
    
    export class Num {
      kind = NodeKind.NUM;
      loc: Position;
      val: number;
    }
    
    export class Parser {
      tok: Token;
    
      constructor(public lexer: Lexer) {}
    
      parseProg() {
        const node = new Prog();
        node.loc = this.lexer.source.getPos();
        while (true) {
          const stmt = this.parseStmt();
          if (stmt) node.body.push(stmt);
          else break;
        }
        return node;
      }
    
      parseStmt() {
        if (this.lexer.source.eof()) return null;
        return this.parseEchoStmt();
      }
    
      parseEchoStmt() {
        const node = new EchoStmt();
        const tok = this.must(TokenKind.ECHO);
        node.loc = tok.loc;
        node.expr = this.parseExpr();
        return node;
      }
    
      parseExpr() {
        if (this.ahead(TokenKind.STR)) return this.parseStr();
        return this.parseAddExpr();
      }
    
      parseStr() {
        const node = new Str();
        const tok = this.lexer.next();
        node.loc = tok.loc;
        node.val = tok.value;
        return node;
      }
    
      parseAddExpr() {
        let left = this.parseMulExpr();
        while (this.ahead([TokenKind.ADD, TokenKind.SUB])) {
          const node = new BinExpr();
          node.op = this.lexer.next().kind;
          node.loc = left.loc;
          node.lhs = left;
          node.rhs = this.parseMulExpr();
          left = node;
        }
        return left;
      }
    
      parseMulExpr() {
        let left = this.parseNum();
        while (this.ahead([TokenKind.MUL, TokenKind.DIV, TokenKind.MOD])) {
          const node = new BinExpr();
          node.op = this.lexer.next().kind;
          node.loc = left.loc;
          node.lhs = left;
          node.rhs = this.parseNum();
          left = node;
        }
        return left;
      }
    
      parseNum(): Node {
        const tok = this.must(TokenKind.NUM);
        const node = new Num();
        node.loc = tok.loc;
        node.val = parseInt(tok.value, 10);
        return node;
      }
    
      must(kind: TokenKind | TokenKind[]) {
        const tok = this.lexer.next();
        if (
          (Array.isArray(kind) && !kind.includes(tok.kind)) ||
          tok.kind !== kind
        ) {
          throw new Error(
            `Unexpected token: ${tok.kind} at ${tok.loc.line}:${tok.loc.col}`
          );
        }
        return tok;
      }
    
      ahead(kind: TokenKind | TokenKind[]) {
        const state = this.lexer.source.getState();
        const tok = this.lexer.next();
        this.lexer.source.setState(state);
        if (Array.isArray(kind)) return kind.includes(tok.kind);
        return tok.kind === kind;
      }
    }

我们可以加入几个单测：

*   `echo 1 + 2`
    
*   `echo 1 + 2 + 3`
    
*   `echo 1 + 2 * 3`
    
*   `echo 1 * 2 + 3`
    

测试步骤为：

*   解析上面的代码
    
*   逐级验证 AST 中的节点是否和我们预期的一致
    

点击展开

    if (Deno.env.get("TEST") === "parser") {
      let s = new Source(`echo 1 + 2`);
      let lexer = new Lexer(s);
      let parser = new Parser(lexer);
    
      let prog = parser.parseProg();
      console.assert(prog.body[0].kind === NodeKind.ECHO, "echo");
      let echo = prog.body[0] as EchoStmt;
      console.assert(echo.expr.kind === NodeKind.BIN, "echo bin");
      let bin = echo.expr as BinExpr;
      console.assert(bin.op === TokenKind.ADD, "add");
      console.assert((bin.lhs as Num).val === 1, "1");
      console.assert((bin.rhs as Num).val === 2, "2");
    
      s = new Source(`echo 1 + 2 + 3`);
      lexer = new Lexer(s);
      parser = new Parser(lexer);
    
      prog = parser.parseProg();
      console.assert(prog.body[0].kind === NodeKind.ECHO, "echo");
      echo = prog.body[0] as EchoStmt;
      console.assert(echo.expr.kind === NodeKind.BIN, "echo bin");
      bin = echo.expr as BinExpr;
      console.assert(bin.op === TokenKind.ADD, "+ 3");
      console.assert((bin.rhs as Num).val === 3, "3");
      bin = bin.lhs as BinExpr;
      console.assert(bin.op === TokenKind.ADD, "1 + 2");
      console.assert((bin.lhs as Num).val === 1, "1");
      console.assert((bin.rhs as Num).val === 2, "2");
    
      s = new Source(`echo 1 + 2 * 3`);
      lexer = new Lexer(s);
      parser = new Parser(lexer);
    
      prog = parser.parseProg();
      console.assert(prog.body[0].kind === NodeKind.ECHO, "echo");
      echo = prog.body[0] as EchoStmt;
      console.assert(echo.expr.kind === NodeKind.BIN, "echo bin");
      bin = echo.expr as BinExpr;
      console.assert(bin.op === TokenKind.ADD, "1 +");
      console.assert((bin.lhs as Num).val === 1, "1");
      bin = bin.rhs as BinExpr;
      console.assert(bin.op === TokenKind.MUL, "2 * 3");
      console.assert((bin.lhs as Num).val === 2, "2");
      console.assert((bin.rhs as Num).val === 3, "3");
    
      s = new Source(`echo 1 * 2 + 3`);
      lexer = new Lexer(s);
      parser = new Parser(lexer);
    
      prog = parser.parseProg();
      console.assert(prog.body[0].kind === NodeKind.ECHO, "echo");
      echo = prog.body[0] as EchoStmt;
      console.assert(echo.expr.kind === NodeKind.BIN, "echo bin");
      bin = echo.expr as BinExpr;
      console.assert(bin.op === TokenKind.ADD, "+ 3");
      console.assert((bin.rhs as Num).val === 3, "3");
      bin = bin.lhs as BinExpr;
      console.assert(bin.op === TokenKind.MUL, "1 * 2");
      console.assert((bin.lhs as Num).val === 1, "1");
      console.assert((bin.rhs as Num).val === 2, "2");
    }

可以将上面的内容粘贴到 `Parser` 的底部，然后通过下面的命令执行单测：

    export TEST=parser && deno run --allow-env parser.ts && echo $?
    

看到控制台输出 0 的话即表示单测通过。

如果我们在单测中打印 `echo 1 * 2 + 3` 对应的 AST，可以看到类似下面的输出：

    {
      "kind": "PROG",
      "loc": {
        "ofst": 0,
        "line": 1,
        "col": 0
      },
      "body": [
        {
          "kind": "ECHO_STMT",
          "loc": {
            "ofst": 0,
            "line": 1,
            "col": 0
          },
          "expr": {
            "kind": "BIN_EXPR",
            "loc": {
              "ofst": 5,
              "line": 1,
              "col": 5
            },
            "op": "ADD",
            "lhs": {
              "kind": "BIN_EXPR",
              "loc": {
                "ofst": 5,
                "line": 1,
                "col": 5
              },
              "op": "MUL",
              "lhs": {
                "kind": "NUM",
                "loc": {
                  "ofst": 5,
                  "line": 1,
                  "col": 5
                },
                "val": 1
              },
              "rhs": {
                "kind": "NUM",
                "loc": {
                  "ofst": 9,
                  "line": 1,
                  "col": 9
                },
                "val": 2
              }
            },
            "rhs": {
              "kind": "NUM",
              "loc": {
                "ofst": 13,
                "line": 1,
                "col": 13
              },
              "val": 3
            }
          }
        }
      ]
    }
    

小结
--

回顾本节，我们通过编写 `echo` 语言的解析器，演示了解析器的核心工作原理：

*   首先，为了结构化解析器，解析过程被拆分为词法解析和语法解析
    
*   词法解析时可以顺便处理源码的行列信息
    
*   对于语法解析，大部分情况下只需根据语法规则，使用递归下降的形式编排函数来复刻语法规则之间的关系
    
    语言规范一般会给出方便实现的语法规则形式，但如果遇到包含左递归语法规则，手写递归下降时需对其进行转换。
    
*   在解析表达式时，可以通过设定操作符的优先级与结合性来确定执行顺序
    

由于 `echo` 语言本身非常简单，对一些比较高级的语法功能的解析，将在后面的章节中、结合引擎源码来介绍。